---
title: "Modsoccs EA Connectivity"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r, message=FALSE, warning=FALSE, results=FALSE}
library(splitstackshape)
library(stringr)
library(tidyr)
library(dplyr)
library(corrr)
library(psych)
library(tableone)
library(corrplot)
library(ggplot2)

```

```{r, warning=FALSE, results=FALSE}
# find ses 1 EA time series files  # pattern glob2rx("sub*_ses-01_EA_2mm_noGSR_schaefer1000_17net_meants.csv")
setwd("/projects/loliver/ModSoCCS/data/processed")
files_ea_ts1 <- list.files(path= ".", recursive=T, full.names=F, pattern="^sub.*_ses-01_EA_2mm_noGSR_schaefer1000_17net_meants\\.csv$")

# confirm csvs aren't empty
files_ea_ts1[file.size(files_ea_ts1) == 0]

# create list of IDs
ptlist1 <- paste("SPN20", substring(files_ea_ts1,5,7), substring(files_ea_ts1,8,11), sep = "_")

# read in time series files 
ea_ts1 <- lapply(files_ea_ts1, read.csv, header=F)

# transpose dfs
ea_ts1 <- lapply(ea_ts1, t)

# Name dfs with participant IDs
names(ea_ts1) <- ptlist1

# CMH participants have 1380 time points; MRP and ZHP have 1406
# drop last 13 time points from each EA run for MRP and ZHP participants (not CMH) to align with CMH; not losing any task 
for (i in names(ea_ts1[13:37])) {                  # need to change values depending on where MRP participants start
  ea_ts1[[i]] <- ea_ts1[[i]][c(1:690,704:1393),]
}

```

```{r}
# find circles onsets for each participant for ses 1 
setwd("/projects/loliver/ModSoCCS/data/processed")

# pattern glob2rx("sub*/ses-01/sub*_circles.1D")
files_circles <- list.files(path= ".", recursive=T, full.names=F, pattern="^sub.*_circles\\.1D$")

# keep only ses-01
files_circles1 <- str_subset(files_circles, pattern="ses-01")

# create list of IDs
circ_ptlist1 <- paste("SPN20", substring(files_circles1,5,7), substring(files_circles1,8,11), sep = "_")

# read in circles files
circles1 <- lapply(files_circles1, read.csv, header=F, sep=" ", colClasses=c(NA, NA, "NULL"))
names(circles1) <- circ_ptlist1

# get circles onset times into same row, adding 552 s per run (690 TRs/run), dividing by 0.8 (as TRs are 0.8s) to get TR onsets 
# not adding 0.4 s as no slice timing correction done with fmriprep 
circles_times1 <- list()

for (i in names(circles1)) {
  circles_times1[[i]] <- round(((cbind(circles1[[i]][1,],(circles1[[i]][2,])+552))/0.8))   ### HERE
}

# remove circles from time series data (circles runs are 50 TRs or 40 s - this way we are removing 50 TRs - the onset + 49)
ea_resid_ts1 <- list()

for (i in names(ea_ts1)) {
  ea_resid_ts1[[i]] <- ea_ts1[[i]][-c(circles_times1[[i]][1,1]:(circles_times1[[i]][1,1]+49),circles_times1[[i]][1,2]:(circles_times1[[i]][1,2]+49),
                         circles_times1[[i]][1,3]:(circles_times1[[i]][1,3]+49),circles_times1[[i]][1,4]:(circles_times1[[i]][1,4]+49)),]
}


# check dims
#lapply(ea_resid_ts1, dim)

# check for NAs
#for (i in names(ea_resid_ts1)) {
#  print (i)
#  print(which(is.na(ea_resid_ts1[[i]])))
#}

```

```{r, warning=FALSE, results=FALSE}
# find ses 2 EA time series files  # pattern glob2rx("sub*_ses-02_EA_2mm_noGSR_schaefer1000_17net_meants.csv")
setwd("/projects/loliver/ModSoCCS/data/processed")
files_ea_ts2 <- list.files(path= ".", recursive=T, full.names=F, pattern="^sub.*_ses-02_EA_2mm_noGSR_schaefer1000_17net_meants\\.csv$")

# confirm csvs aren't empty
files_ea_ts2[file.size(files_ea_ts2) == 0]

# create list of IDs
ptlist2 <- paste("SPN20", substring(files_ea_ts2,5,7), substring(files_ea_ts2,8,11), sep = "_")

# read in time series files 
ea_ts2 <- lapply(files_ea_ts2, read.csv, header=F)

# transpose dfs
ea_ts2 <- lapply(ea_ts2, t)

# Name dfs with participant IDs
names(ea_ts2) <- ptlist2

# CMH participants have 1380 time points; MRP and ZHP have 1406 
# drop last 13 time points from each EA run for MRP and ZHP participants (not CMH) to align with CMH; not losing any task 
for (i in names(ea_ts2[13:39])) {                  # need to change values depending on where MRP participants start
  ea_ts2[[i]] <- ea_ts2[[i]][c(1:690,704:1393),]
}

# keep only those with both baseline and longitudinal data - might want to do this down the line
#ea_ts2 <- ea_ts2[names(ea_ts2) %in% names(ea_ts1)]

```

```{r}
# find circles onsets for each participant for ses 2 
setwd("/projects/loliver/ModSoCCS/data/processed")

# pattern glob2rx("sub*/ses-02/sub*_circles.1D")
files_circles <- list.files(path= ".", recursive=T, full.names=F, pattern="^sub.*_circles\\.1D$")

# keep only ses-02
files_circles2 <- str_subset(files_circles, pattern="ses-02")

# create list of IDs
circ_ptlist2 <- paste("SPN20", substring(files_circles2,5,7), substring(files_circles2,8,11), sep = "_")

# read in circles files
circles2 <- lapply(files_circles2, read.csv, header=F, sep=" ", colClasses=c(NA, NA, "NULL"))
names(circles2) <- circ_ptlist2

# get circles onset times into same row, adding 552 s per run (690 TRs/run), dividing by 0.8 (as TRs are 0.8s) to get TR onsets 
# not adding 0.4 s as no slice timing correction done with fmriprep 
circles_times2 <- list()

for (i in names(circles2)) {
  circles_times2[[i]] <- round(((cbind(circles2[[i]][1,],(circles2[[i]][2,])+552))/0.8))  
}

# remove circles from time series data (circles runs are 50 TRs or 40 s - this way we are removing 50 TRs - the onset + 49)
ea_resid_ts2 <- list()

for (i in names(ea_ts2)) {
  ea_resid_ts2[[i]] <- ea_ts2[[i]][-c(circles_times2[[i]][1,1]:(circles_times2[[i]][1,1]+49),circles_times2[[i]][1,2]:(circles_times2[[i]][1,2]+49),
                         circles_times2[[i]][1,3]:(circles_times2[[i]][1,3]+49),circles_times2[[i]][1,4]:(circles_times2[[i]][1,4]+49)),]
}


# check dims
#lapply(ea_resid_ts2, dim)

# check for NAs
#for (i in names(ea_resid_ts2)) {
#  print (i)
#  print(which(is.na(ea_resid_ts2[[i]])))
#}

```

```{r}
# read in Modsoccs behavioural data (this file has false TASIT 0s manually changed to NAs)
mod_data <- read.csv(file = "/projects/loliver/ModSoCCS/data/behavioural/ModSoCCS_data_10-24-2022_NAs.csv", header=T) %>%
  mutate(site = as.factor(site),
         demo_sex_birth = as.factor(demo_sex_birth),
         scid5_cat3_scz = as.factor(scid5_cat3_scz)) 

# filter based on early termination (keep completers only)
mod_data <- mod_data[mod_data$term_premature_yn == 0,]

# EA task QC ha not been done like it was in SPINS, but know CMH0001 session 1 would fail for sure (no presses across 4 EA runs and all circles)

# checked participants.tsv file and everything has passed aside from ZHP007 session 2 being uncertain (need to look into this, included for now)

# read in new exclusion list based on EA task, motion, and imaging (fmriprep and ciftify) QC (see ) ### from SPINS
#exclude_list <- read.csv(file="/projects/loliver/SPINS_PLS_Conn/data/processed/EA_QC_exclusion_list_10-19-2021.csv", header=F)##

# keep conn data for eligible participants who passed QC
#ea_resid_ts1 <- ea_resid_ts1[!(names(ea_resid_ts1) %in% mod_data$record_id)]
#ea_resid_ts2 <- ea_resid_ts2[!(names(ea_resid_ts2) %in% mod_data$record_id)]

```

```{r}
# read in Schaefer 1000 ROI labels 
rois_s1000_17net <- read.table(file = "/projects/loliver/ModSoCCS/data/parcellations/Schaefer2018_1000Parcels_17Networks_order_labeltable.txt", header=F)

# separate column to get parcellation, hemi, and roi variables
#rois_s1000_17net <- data.frame(rois_s1000_17net)
rois_s1000_17net <- separate(rois_s1000_17net, V1, into=c("parcellation","hemi","label"), sep=c("_","_"), extra="merge")
rois_s1000_17net <- separate(rois_s1000_17net, label, into=c("network"), sep=c("_","_"), extra="drop", remove=F)
rois_s1000_17net$network <- as.factor(rois_s1000_17net$network)

#read in Schaefer 1000 and neurosynth mentalizing overlap values (z scores)
overlap_s1000_17net_ment <- read.table(file = "/projects/jjeyachandra/modsoccs/modsoccs-meet_2022-11-04/neurosynth_on_participant_surface/output/mentalizing_Schaefer2018_1000Parcels_17Networks_order.txt", header=F)

rois_s1000_17net$ment_overlap <- overlap_s1000_17net_ment$V1

# check number of edges/ROIs retained with overlap thresholds of 1 and 2 
dim(rois_s1000_17net[rois_s1000_17net$ment_overlap>1,]) # 85 - use this, but could maybe go lower?
dim(rois_s1000_17net[rois_s1000_17net$ment_overlap>2,]) # 40

```



```{r}
# generate ses 01 correlation matrices for each participant
cor_ea1  <- lapply(ea_resid_ts1, cor)

# fisher z transform corrs to normalize dist
cor_ea1_z  <- lapply(cor_ea1, fisherz)

# add ROI names and replace inf values with 0 
for (i in names(cor_ea1_z)) {
  colnames(cor_ea1_z[[i]]) <- as.vector(rois_s1000_17net$label)
  rownames(cor_ea1_z[[i]]) <- as.vector(rois_s1000_17net$label)
  cor_ea1_z[[i]][is.infinite(cor_ea1_z[[i]])] <- 0
}

# check out negative values - about % negative (total length: ; GSR not applied)
#for (i in names(cor_rs1_z)){
#  print((length(cor_rs1_z[[i]][cor_rs1_z[[i]]<0])))
#  print(summary(cor_rs1_z[[i]][cor_rs1_z[[i]]<0]))
#}

# check for NAs  - they exist - check again after filtering for mentalizing network ROIs
#for (i in names(cor_ea1_z)){
#  print(cor_ea1_z[[i]][is.na(cor_ea1_z[[i]])])
#}

# mentalizing ROIs only
ment_ea1_z <- lapply(cor_ea1_z, "[", c(rois_s1000_17net[rois_s1000_17net$ment_overlap>1,"label"]), c(rois_s1000_17net[rois_s1000_17net$ment_overlap>1,"label"]))

# check for NAs  - none
for (i in names(ment_ea1_z)){
  print(ment_ea1_z[[i]][is.na(ment_ea1_z[[i]])])
}

# calculate mean mentalizing within network conn for each participant
ment_conn1 <- data.frame()
for (i in names(ment_ea1_z)) {
  ment_conn1[i,"pre_mentalizing"] <- mean(ment_ea1_z[[i]][upper.tri(ment_ea1_z[[i]], diag=F)])
}

ment_conn1$record_id <- rownames(ment_conn1)


#mean_conn <- data.frame()
#for (i in names(cor_ea1_z)) {
#  mean_conn[i,"Mentalizing_t1"] <- mean(cor_ea1_z[[i]][rownames(cor_ea1_z[[i]]) %in% (rois[rois$net_ColeAnt=="Subcortical","atlas_roi"]), #colnames(cor_rs1_z[[i]]) %in% (rois[rois$net_ColeAnt=="Subcortical","atlas_roi"])],na.rm=T)
#}
  
```

```{r}
# generate ses 02 correlation matrices for each participant
cor_ea2  <- lapply(ea_resid_ts2, cor)

# fisher z transform corrs to normalize dist
cor_ea2_z  <- lapply(cor_ea2, fisherz)

# add ROI names and replace inf values with 0 
for (i in names(cor_ea2_z)) {
  colnames(cor_ea2_z[[i]]) <- as.vector(rois_s1000_17net$label)
  rownames(cor_ea2_z[[i]]) <- as.vector(rois_s1000_17net$label)
  cor_ea2_z[[i]][is.infinite(cor_ea2_z[[i]])] <- 0
}

# check for NAs  - they exist - check again after filtering for mentalizing network ROIs
#for (i in names(cor_ea2_z)){
#  print(cor_ea2_z[[i]][is.na(cor_ea2_z[[i]])])
#}

# mentalizing ROIs only
ment_ea2_z <- lapply(cor_ea2_z, "[", c(rois_s1000_17net[rois_s1000_17net$ment_overlap>1,"label"]), c(rois_s1000_17net[rois_s1000_17net$ment_overlap>1,"label"]))

# check for NAs  - none
for (i in names(ment_ea2_z)){
  print(ment_ea2_z[[i]][is.na(ment_ea2_z[[i]])])
}

# calculate mean mentalizing within network conn for each participant
ment_conn2 <- data.frame()
for (i in names(ment_ea2_z)) {
  ment_conn2[i,"post_mentalizing"] <- mean(ment_ea2_z[[i]][upper.tri(ment_ea2_z[[i]], diag=F)])
}

ment_conn2$record_id <- rownames(ment_conn2)

```


```{r}
# merge data to plot mentalizing connectivity data by time
ment_conn_long1 <- ment_conn1[,c(2,1)]
ment_conn_long1$time <- rep("t1",37)
ment_conn_long1 <- merge(mod_data[,c(1,2,6,10,73,82,83,88,90,95,96:117)], ment_conn_long1, by="record_id")  
colnames(ment_conn_long1)[11:33] <- sub("pre_", "", colnames(ment_conn_long1)[11:33])

ment_conn_long2 <- ment_conn2[,c(2,1)]
ment_conn_long2$time <- rep("t2",39)
ment_conn_long2 <- merge(mod_data[,c(1,2,6,10,73,82,83,88,90,95,118:139)], ment_conn_long2, by="record_id") 
colnames(ment_conn_long2)[11:33] <- sub("post_", "", colnames(ment_conn_long2)[11:33])

ment_conn_long <- rbind(ment_conn_long1,ment_conn_long2)


# create df with ment conn difference scores
ment_conn_diff <- merge(ment_conn1, ment_conn2, by="record_id")
ment_conn_diff$diff_mentalizing <- ment_conn_diff$post_mentalizing-ment_conn_diff$pre_mentalizing 
ment_conn_diff <- merge(ment_conn_diff,mod_data[,c(1,2,6,10)],by="record_id")

# add colour variable based on whether there was an increase (green) or decrease (purple) in connectivity from t1 to t2 
ment_conn_diff$colour <- ifelse(ment_conn_diff$diff > 0, "springgreen1","mediumpurple1")

```

```{r fig.height=7, fig.width=6}
# plot mentalizing conn x time  # drop those with only t2 data
ggplot(ment_conn_long[ment_conn_long$record_id!="SPN20_ZHP_0002" & ment_conn_long$record_id!="SPN20_ZHP_0008",], aes(x=time, y=mentalizing)) +    #record_id
  geom_point() +    # aes(shape = PlotLabel)
  geom_line(aes(group=record_id), alpha = 0.5) +   # color=record_id  #color=rep(ment_conn_diff$colour,2)
  geom_smooth(method="lm", fill = "grey40") +   # aes(color = RandomArm), 
  labs(x ="Time", 
       y = "Mean Mentalizing Network Connectivity") +
       #shape = "Status at scan 2",
       #color = "Group") +
  guides(fill=FALSE, color=FALSE) +
  #scale_colour_manual(values = RandomArmColors) +
  #scale_fill_manual(values = RandomArmColors) +
  #scale_shape_manual(values = c(21:23)) +
  scale_x_discrete(expand=c(0.1, 0.1)) +  # add space between time points
  theme_bw() +
  theme(panel.grid.minor = element_blank(), panel.grid.major = element_blank(),text=element_text(size=15))

```

```{r fig.height=6, fig.width=9}
# plot mentalizing conn x time 
ggplot(ment_conn_long[ment_conn_long$record_id!="SPN20_ZHP_0002" & ment_conn_long$record_id!="SPN20_ZHP_0008",], aes(x=time, y=mentalizing)) +  
  geom_point() +    # aes(shape = PlotLabel)
  geom_line(aes(group=record_id), alpha = 0.5) +   # color=record_id  #color=rep(ment_conn_diff$colour,2)
  geom_smooth(method="lm", fill = "grey40") +   # aes(color = RandomArm), 
  labs(x ="Time", 
       y = "Mean Mentalizing Network Connectivity") +
       #shape = "Status at scan 2",
       #color = "Group") +
  guides(fill=FALSE, color=FALSE) +
  #scale_colour_manual(values = RandomArmColors) +
  #scale_fill_manual(values = RandomArmColors) +
  #scale_shape_manual(values = c(21:23)) +
  scale_x_discrete(expand=c(0.1, 0.1)) +  # add space between time points
  facet_wrap(~site) + 
  theme_bw() +
  theme(panel.grid.minor = element_blank(), panel.grid.major = element_blank(),,text=element_text(size=15))

```

```{r fig.height=4.25, fig.width=6}
# boxplot of mean mentalizing conn by time  
ggplot(ment_conn_long, aes(x=time, y=mentalizing, fill=site)) +      # color=site for violin 
     #geom_violin(trim=FALSE) +
     #stat_summary(fun.data=mean_sdl, mult=1, 
    #            geom="crossbar", width=0.05) +
     geom_boxplot(outlier.shape = NA, alpha = 0.0001) + 
     geom_dotplot(binaxis = 'y', stackdir = 'center') +
     #geom_hline(yintercept = 0) +
     labs(x ="Time", 
       y = "Mean Mentalizing Network Connectivity") +
     #scale_fill_manual(values = RandomArmColors) +
     scale_shape_manual(values = c(21)) +
     guides(fill=FALSE, color=FALSE) +
     facet_wrap(~site) + 
     theme_bw() +
     theme(panel.grid.minor.x = element_blank(), panel.grid.major.x = element_blank(),text=element_text(size=14))

```


```{r fig.height=4.25, fig.width=5}
# boxplot of change in mean mentalizing conn by site
ggplot(ment_conn_diff, aes(x=site, y=diff_mentalizing, fill=site)) + #color=site for violin
     #geom_violin(trim=FALSE) +
     geom_boxplot(outlier.shape = NA, alpha = 0.0001) + 
     geom_dotplot(binaxis = 'y', stackdir = 'center') +
     #geom_hline(yintercept = 0) +
     labs(x ="Site", 
       y = "Change in Mentalizing Network Connectivity (t2-t1)") +
     #scale_fill_manual(values = RandomArmColors) +
     scale_shape_manual(values = c(21)) +
     guides(fill=FALSE, color=FALSE) +
 #   facet_wrap(~Region) + 
     theme_bw() +
     theme(panel.grid.minor.x = element_blank(), panel.grid.major.x = element_blank(),text=element_text(size=12))

```

```{r}
# read in EA usability and motion stats
use_data <- read.csv(file = "/projects/jjeyachandra/modsoccs/modsoccs-meet_2022-11-04/motion/motion-stats.csv", header=T)

# change ID to match behav
use_data$record_id <- paste("SPN20", substring(use_data$subject,1,3), substring(use_data$subject,4,7), sep = "_")

# make time var to match other df
use_data$time <- as.factor(ifelse(use_data$session == 1, 't1', 't2'))

# keep only EA data
use_data <- use_data[use_data$task == "emp",c(9,10,2:5)]

# reformat to get a row per session and means across runs for each
mean_use_data <- reshape(use_data, idvar = c("record_id","time"), timevar = "run", direction = "wide")

mean_use_data$mean_fd <- rowMeans(mean_use_data[,c("mean.1","mean.2")])
mean_use_data$percent_use <- rowMeans(mean_use_data[,c("percent_usable.1","percent_usable.2")])  
mean_use_data$minutes <- rowMeans(mean_use_data[,c("minutes.1","minutes.2")])

# drop per run data and pilot IDs
mean_use_data <- mean_use_data[-c(27,28,90),c(1,2,9:11)]

# merge with behavioural data 
mean_use_behav <- merge(mean_use_data,ment_conn_long,by=c("record_id","time"))

# missing IDs - none
unique(ment_conn_long$record_id[!ment_conn_long$record_id %in% mean_use_behav$record_id])

```

```{r fig.height=4.25, fig.width=5}
# boxplots for percent usable data by time and site
ggplot(mean_use_behav, aes(x=time, y=percent_use, fill=time)) + #color=site for violin
     #geom_violin(trim=FALSE) +
     geom_boxplot(outlier.shape = NA, alpha = 0.0001) + 
     geom_dotplot(binaxis = 'y', stackdir = 'center') +
     #geom_hline(yintercept = 0) +
     labs(x ="Time", 
       y = "Percent Usable Data Across EA Runs") +
     #scale_fill_manual(values = RandomArmColors) +
     scale_shape_manual(values = c(21)) +
     guides(fill=FALSE, color=FALSE) +
     facet_wrap(~site) + 
     theme_bw() +
     theme(panel.grid.minor.x = element_blank(), panel.grid.major.x = element_blank(),text=element_text(size=14))


# boxplots for mean FD by site
ggplot(mean_use_behav, aes(x=time, y=mean_fd, fill=time)) + #color=site for violin
     #geom_violin(trim=FALSE) +
     geom_boxplot(outlier.shape = NA, alpha = 0.0001) + 
     geom_dotplot(binaxis = 'y', stackdir = 'center') +
     #geom_hline(yintercept = 0) +
     labs(x = "Time", 
       y = "Mean Framewise Displacement Across EA Runs") +
     #scale_fill_manual(values = RandomArmColors) +
     scale_shape_manual(values = c(21)) +
     guides(fill=FALSE, color=FALSE) +
     facet_wrap(~site) + 
     theme_bw() +
     theme(panel.grid.minor.x = element_blank(), panel.grid.major.x = element_blank(),text=element_text(size=14))

```

```{r fig.height=4, fig.width=6.5}
# correlations between percent usable data and age, bprs, sans, processing speed, and working memory
#cor.test(clin_conn_comb_eps$CORETot_Stab, clin_conn_comb_eps$Bet_Vis2_t1)

# Age
ggplot(mean_use_behav, aes(x=demo_age_study_entry, y=percent_use)) + 
  geom_point(aes(color = site)) + 
  geom_smooth(method="lm", fill = "lightgrey", color="grey") +   # aes(color = RandomArm), 
  labs(x ="Age", 
       y = "Percent Usable Data Across EA Runs",
       color = "Site") +
     #guides(fill=FALSE, color=FALSE) +
     facet_wrap(~time) +
  theme_bw() +
  theme(panel.grid.minor = element_blank(), panel.grid.major = element_blank(),text=element_text(size=15))

# BPRS
ggplot(mean_use_behav, aes(x=bprs_factor_total, y=percent_use)) + 
  geom_point(aes(color = site)) + 
  geom_smooth(method="lm", fill = "lightgrey", color="grey") +   # aes(color = RandomArm), 
  labs(x ="BPRS Total", 
       y = "Percent Usable Data Across EA Runs",
       color = "Site") +
     #guides(fill=FALSE, color=FALSE) +
     facet_wrap(~time) +
  theme_bw() +
  theme(panel.grid.minor = element_blank(), panel.grid.major = element_blank(),text=element_text(size=15))

# SANS
ggplot(mean_use_behav, aes(x=sans_total_sc, y=percent_use)) + 
  geom_point(aes(color = site)) + 
  geom_smooth(method="lm", fill = "lightgrey", color="grey") +   # aes(color = RandomArm), 
  labs(x ="SANS Total", 
       y = "Percent Usable Data Across EA Runs",
       color = "Site") +
     #guides(fill=FALSE, color=FALSE) +
     facet_wrap(~time) +
  theme_bw() +
  theme(panel.grid.minor = element_blank(), panel.grid.major = element_blank(),text=element_text(size=15))

# processing speed
ggplot(mean_use_behav, aes(x=np_domain_tscore_process_speed, y=percent_use)) + 
  geom_point(aes(color = site)) + 
  geom_smooth(method="lm", fill = "lightgrey", color="grey") +   # aes(color = RandomArm), 
  labs(x ="Processing Speed Domain Score", 
       y = "Percent Usable Data Across EA Runs",
       color = "Site") +
     #guides(fill=FALSE, color=FALSE) +
     facet_wrap(~time) +
  theme_bw() +
  theme(panel.grid.minor = element_blank(), panel.grid.major = element_blank(),text=element_text(size=15))

# working memory 
ggplot(mean_use_behav, aes(x=np_domain_tscore_work_mem, y=percent_use)) + 
  geom_point(aes(color = site)) + 
  geom_smooth(method="lm", fill = "lightgrey", color="grey") +   # aes(color = RandomArm), 
  labs(x ="Working Memory Domain Score", 
       y = "Percent Usable Data Across EA Runs",
       color = "Site") +
     #guides(fill=FALSE, color=FALSE) +
     facet_wrap(~time) +
  theme_bw() +
  theme(panel.grid.minor = element_blank(), panel.grid.major = element_blank(),text=element_text(size=15))

```




Same as above with ComBat.

```{r, results=FALSE, message=FALSE}
# prep to run ComBat on baseline data

# add labels to df columns - this will ensure the order is maintained once the data is projected back to an adjacency matrix post-combat
for (i in names(RS_ts1)) {
  colnames(RS_ts1[[i]]) <- rois$order
  RS_ts1[[i]] <- data.frame(RS_ts1[[i]])
}

# generate baseline correlation matrices for each participant for use in Combat
rs1_cor <- lapply(RS_ts1, correlate)

# set upper triangle to NA
rs1_cor <- lapply(rs1_cor, shave)

# create dfs with corrs for each participant
rs1_cor_str <- lapply(rs1_cor, stretch, na.rm=F)
rs1_cor_stru <- lapply(rs1_cor_str, unite, col="rois", 1:2, sep="-", remove=T)
rs1_cor_df <- lapply(rs1_cor_stru, data.frame)

# change col 1 to row names and transpose to get each participant's data in one row
cor_names <- as.vector(rs1_cor_df[[1]][,1])

for (i in names(rs1_cor_df)) {
  rs1_cor_df[[i]] <- data.frame(rs1_cor_df[[i]][,2])
  rs1_cor_df[[i]] <- t(rs1_cor_df[[i]])
  colnames(rs1_cor_df[[i]]) <- cor_names
}

# bind rows across df list to generate tibble with all corrs for each participant
rs1_corrs <- do.call("rbind",rs1_cor_df)
rownames(rs1_corrs) <- names(rs1_cor_df)

# remove columns with only NAs
rs1_corrs <- rs1_corrs[,colSums(is.na(rs1_corrs)) != nrow(rs1_corrs)]

# fisher z transform corrs
rs1_corrs_z  <- fisherz(rs1_corrs)

```

```{r}
# run ComBat on baseline connectivity data to harmonize across scanners
library(neuroCombat)

# change subids as data frame variable names can't start with a number
# dat is a data matrix of the data to harmonize - rows are features (connections) and columns are participants
rownames(rs1_corrs_z) <- paste("sub", rownames(rs1_corrs_z), sep = "_")
rs1_corrs_com <- as.matrix(t(rs1_corrs_z))

# mod is a design matrix specifying biological covariates that should be protected - here treatment arm, sex, age
# order of conn data is not the same as clinical data   
modcombat <- model.matrix(~ RandomArm + sex + age, data=stpd_clin)

# R run ComBat
# batch is a vector (length should be equal to the number of columns in the data matrix) that specifies the id for the batch, site, or scanner to correct for
rs1_combat <- neuroCombat(dat=rs1_corrs_com, batch=as.vector(stpd_clin$site), mod=modcombat)

# add rois column to harmonized data frame and separate
rs1_combat_data <- data.frame(rs1_combat$dat.combat)
rs1_combat_data$rois <- rownames(rs1_combat_data)
rs1_combat_data <- rs1_combat_data %>% separate(rois, into=c("to","from"), sep="-")

library(netdiffuseR)
# rename columns
edgelist <- rs1_combat_data[,c("to","from")]
colnames(edgelist) <- c("ego","alter")

# convert unique edge list back to adjacency matrix for each participant - Note: edgelist_to_adjmat sorts the edges alphabetically
rs1_combat_list <- list()

for (i in colnames(rs1_combat_data[,1:58])) {
  rs1_combat_list[[i]] <- as.matrix(edgelist_to_adjmat(edgelist,w=as.vector(rs1_combat_data[,i]),undirected=T))
  colnames(rs1_combat_list[[i]]) <- rois$atlas_roi
  rownames(rs1_combat_list[[i]]) <- rois$atlas_roi
}

# remove sub_ in IDs 
names(rs1_combat_list) <- c(stpd_clin$STUDYID)

# cortical ROIs only 
rs1_combat_list_cort <- lapply(rs1_combat_list, "[", 33:392, 33:392)

# subcortical ROIs only
rs1_combat_list_sub <- lapply(rs1_combat_list, "[", 1:32, 1:32)

# check out negative values - about 50% negative (total length: 153664; keep in mind GSR applied)
for (i in names(rs1_combat_list)){
  print((length(rs1_combat_list[[i]][rs1_combat_list[[i]]<0])))
  print(summary(rs1_combat_list[[i]][rs1_combat_list[[i]]<0]))
}

# check for NAs - none
for (i in names(rs1_combat_list)){
  print(rs1_combat_list[[i]][is.na(rs1_combat_list[[i]])])
}

# write unthresholded individual conn matrices for use in matlab (BCT) 
#setwd("/projects/loliver/STOPPD_Long_FC/data/processed/conn_matrices/combat/ses-01")

#for (i in names(rs1_combat_list)) {
#  write.table(rs1_combat_list[[i]],file=paste0(i,"_whole.csv"),row.names = F,col.names = F,sep=",")   
#}

# cortical ROIs only
#for (i in names(rs1_combat_list_cort)) {
#  write.table(rs1_combat_list_cort[[i]],file=paste0(i,"_cortical.csv"),row.names = F,col.names = F,sep=",")   
#}

# subcortical ROIs only
#for (i in names(rs1_combat_list_sub)) {
#  write.table(rs1_combat_list_sub[[i]],file=paste0(i,"_subcortical.csv"),row.names = F,col.names = F,sep=",")   
#}

```

```{r, results=FALSE, message=FALSE}
# prep to run ComBat on longitudinal data

# add labels to df columns - this will ensure the order is maintained once the data is projected back to an adjacency matrix post-combat
for (i in names(RS_ts2)) {
  colnames(RS_ts2[[i]]) <- rois$order
  RS_ts2[[i]] <- data.frame(RS_ts2[[i]])
}

# generate longitudinal correlation matrices for each participant for use in Combat
rs2_cor <- lapply(RS_ts2, correlate)

# set upper triangle to NA
rs2_cor <- lapply(rs2_cor, shave)

# create dfs with corrs for each participant
rs2_cor_str <- lapply(rs2_cor, stretch, na.rm=F)
rs2_cor_stru <- lapply(rs2_cor_str, unite, col="rois", 1:2, sep="-", remove=T)
rs2_cor_df <- lapply(rs2_cor_stru, data.frame)

# change col 1 to row names and transpose to get each participant's data in one row
cor_names2 <- as.vector(rs2_cor_df[[1]][,1])

for (i in names(rs2_cor_df)) {
  rs2_cor_df[[i]] <- data.frame(rs2_cor_df[[i]][,2])
  rs2_cor_df[[i]] <- t(rs2_cor_df[[i]])
  colnames(rs2_cor_df[[i]]) <- cor_names2
}

# bind rows across df list to generate tibble with all corrs for each participant
rs2_corrs <- do.call("rbind",rs2_cor_df)
rownames(rs2_corrs) <- names(rs2_cor_df)

# remove columns with only NAs
rs2_corrs <- rs2_corrs[,colSums(is.na(rs2_corrs)) != nrow(rs2_corrs)]

# fisher z transform corrs
rs2_corrs_z  <- fisherz(rs2_corrs)

```

```{r}
# run ComBat on longitudinal connectivity data to harmonize across scanners
library(neuroCombat)

# change subids as data frame variable names can't start with a number
# dat is a data matrix of the data to harmonize - rows are features (connections) and columns are participants
rownames(rs2_corrs_z) <- paste("sub", rownames(rs2_corrs_z), sep = "_")
rs2_corrs_com <- as.matrix(t(rs2_corrs_z))

# mod is a design matrix specifying biological covariates that should be protected - here treatment arm, sex, age
# order of conn data is not the same as clinical data   
modcombat <- model.matrix(~ RandomArm + sex + age, data=stpd_clin)

# R run ComBat # same error when try with svapkg ComBat function
# batch is a vector (length should be equal to the number of columns in the data matrix) that specifies the id for the batch, site, or scanner to correct for
rs2_combat <- neuroCombat(dat=rs2_corrs_com, batch=as.vector(stpd_clin$site), mod=modcombat)

# add rois column to harmonized data frame and separate
rs2_combat_data <- data.frame(rs2_combat$dat.combat)
rs2_combat_data$rois <- rownames(rs2_combat_data)
rs2_combat_data <- rs2_combat_data %>% separate(rois, into=c("to","from"), sep="-")

library(netdiffuseR)
# rename columns
edgelist <- rs2_combat_data[,c("to","from")]
colnames(edgelist) <- c("ego","alter")

# convert unique edge list back to adjacency matrix for each participant - Note: edgelist_to_adjmat sorts the edges alphabetically
rs2_combat_list <- list()

for (i in colnames(rs2_combat_data[,1:58])) {
  rs2_combat_list[[i]] <- as.matrix(edgelist_to_adjmat(edgelist,w=as.vector(rs2_combat_data[,i]),undirected=T))
  colnames(rs2_combat_list[[i]]) <- rois$atlas_roi
  rownames(rs2_combat_list[[i]]) <- rois$atlas_roi
}

# remove sub_ in IDs 
names(rs2_combat_list) <- c(stpd_clin$STUDYID)

# cortical ROIs only 
rs2_combat_list_cort <- lapply(rs2_combat_list, "[", 33:392, 33:392)

# subcortical ROIs only
rs2_combat_list_sub <- lapply(rs2_combat_list, "[", 1:32, 1:32)

# check out negative values - about 50% negative (total length: 153664; keep in mind GSR applied)
for (i in names(rs2_combat_list)){
  print((length(rs2_combat_list[[i]][rs2_combat_list[[i]]<0])))
  print(summary(rs2_combat_list[[i]][rs2_combat_list[[i]]<0]))
}

# check for NAs - none
for (i in names(rs2_combat_list)){
  print(rs2_combat_list[[i]][is.na(rs2_combat_list[[i]])])
}

# write unthresholded individual conn matrices for use in matlab (BCT) 
#setwd("/projects/loliver/STOPPD_Long_FC/data/processed/conn_matrices/combat/ses-02")

#for (i in names(rs2_combat_list)) {
#  write.table(rs2_combat_list[[i]],file=paste0(i,"_whole.csv"),row.names = F,col.names = F,sep=",")   
#}

# cortical ROIs only
#for (i in names(rs2_combat_list_cort)) {
#  write.table(rs2_combat_list_cort[[i]],file=paste0(i,"_cortical.csv"),row.names = F,col.names = F,sep=",")   
#}

# subcortical ROIs only
#for (i in names(rs2_combat_list_sub)) {
#  write.table(rs2_combat_list_sub[[i]],file=paste0(i,"_subcortical.csv"),row.names = F,col.names = F,sep=",")   
#}

```



Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.